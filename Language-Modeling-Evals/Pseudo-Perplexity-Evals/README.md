# Pseudo-Perplexity Evaluations
We evaluate our Masked Language Models (MLMs) using the **Pseudo-Perplexity** metric, introduced by [Salazar et al. (2020)](https://aclanthology.org/2020.acl-main.240/). We believe that the frequently used Perplexity metric is not suitable for the MLMs but more suitable for the Causal Language Models (CLMs).

We share our implementation of the Pseudo-Perplexity metric here at [pseudo_ppl.py](https://github.com/SaiedAlshahrani/performance-implications/blob/main/Language-Modeling-Evals/Pseudo-Perplexity-Evals/pseudo_ppl.py) and share as well the Pseudo-Perplexity evaluations of our MLMs here at [Pseudo-Perplexity-Metric.ipynb](https://github.com/SaiedAlshahrani/performance-implications/blob/main/Language-Modeling-Evals/Pseudo-Perplexity-Evals/Pseudo-Perplexity-Metric.ipynb).