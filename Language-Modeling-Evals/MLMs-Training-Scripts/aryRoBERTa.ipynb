{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ffeb994-080c-4d73-ac51-2ee24151b84e",
   "metadata": {},
   "source": [
    "## Masked Language Model for __Moroccan Arabic Wikipedia__ (aryRoBERTa<sub>BASE</sub>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827606b-4a59-463f-8333-a7b5b959bc1e",
   "metadata": {},
   "source": [
    "### * Environment Setups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a68b8b00-ec74-4c1a-a11e-cbccbc48c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, warnings \n",
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_warning()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"True\"\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e00891-0f61-4925-a967-89dd0b7ff5d7",
   "metadata": {},
   "source": [
    "### * Hugging Face Setups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f37b56d-c48a-48f4-b4d3-51ec768186b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /root/.huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "! git config --global credential.helper store\n",
    "\n",
    "arywiki_hf_token='hf_XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' # Use your huggingface token here\n",
    "login(token=arywiki_hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c9dc4-c20b-4af4-8d31-864143daa8b4",
   "metadata": {},
   "source": [
    "### * Create Hugging Face Repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2000dc35-97d6-4602-8f8a-c7a106921604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mgit version 2.25.1\u001b[0m\n",
      "\u001b[90mgit-lfs/2.9.2 (GitHub; linux amd64; go 1.13.5)\u001b[0m\n",
      "\n",
      "You are about to create \u001b[1mSaiedAlshahrani/aryRoBERTa\u001b[0m\n",
      "\n",
      "Your repo now lives at:\n",
      "  \u001b[1mhttps://huggingface.co/SaiedAlshahrani/aryRoBERTa\u001b[0m\n",
      "\n",
      "You can clone it locally with the command below, and commit/push as usual.\n",
      "\n",
      "  git clone https://huggingface.co/SaiedAlshahrani/aryRoBERTa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! huggingface-cli repo create aryRoBERTa -y # Create a new repo on your huggingface account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3031a437-8c91-410b-9c2c-64a7e6ac2fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'aryRoBERTa'...\n",
      "remote: Enumerating objects: 3, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
      "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (3/3), 421 bytes | 140.00 KiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://huggingface.co/SaiedAlshahrani/aryRoBERTa # Clone the new repo from your huggingface account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7343b46d-5ce2-42f3-b87d-05403547a854",
   "metadata": {
    "tags": []
   },
   "source": [
    "### * Train Byte-level Tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66b0b25d-710e-4e80-9e47-75b892416996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "wiki_corpus = 'arywiki-20230101-pages-articles-processed.txt' # Use your preprocessed Wikipedia Corpus here\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "tokenizer.train(\n",
    "    files=wiki_corpus, \n",
    "    vocab_size=52_000, min_frequency=2, \n",
    "    special_tokens=['<s>', '<pad>', '</s>', '<unk>', '<mask>']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e78a2da-cdb7-49a4-bfa5-f55679f6094b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aryRoBERTa/vocab.json', 'aryRoBERTa/merges.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_model('aryRoBERTa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0e5ad91-d78b-44e4-ae25-0806d6ea813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"aryRoBERTa\", max_length=512, padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1482672e-9c30-4a12-ac90-62ac10d6c8a3",
   "metadata": {},
   "source": [
    "### * Initialize aryRoberta Model for MLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "654b12fb-24ea-4af0-b4a4-271e16a9e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=52_000, max_position_embeddings=514,\n",
    "    num_attention_heads=12, num_hidden_layers=6, type_vocab_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62ad7dc8-934e-44fa-9aeb-e7f0494f92f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM\n",
    "\n",
    "model = RobertaForMaskedLM(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da7d156d-b584-40df-bcdb-958330bee94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Number of Trainable Parameters: 83,504,416\n"
     ]
    }
   ],
   "source": [
    "print(f\"# Number of Trainable Parameters: {format(model.num_parameters(),',d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3574fe7-1fbd-48a3-91b0-5c8697893502",
   "metadata": {},
   "source": [
    "### * Prepare Moroccan Arabic Corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e44bba4d-00cb-41e8-9708-5597e8a10634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Total Number of Samples: 4,674\n"
     ]
    }
   ],
   "source": [
    "with open(wiki_corpus, 'r', encoding='utf-8') as f: \n",
    "    arywiki_corpus = f.read().split('\\n')\n",
    "\n",
    "print(f'# Total Number of Samples: {format(len(arywiki_corpus),\",d\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e939deb-ded9-4932-a5f4-f3727bdcecc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "arywiki_20230101 = pd.DataFrame(data={\"text\": arywiki_corpus})\n",
    "arywiki_20230101.to_csv(\"aryRoBERTa/Moroccan_Arabic_Wikipedia__aryRoBERTa.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311884cc-7709-4685-a0fd-a4bc0cf436d1",
   "metadata": {},
   "source": [
    "### * Push Moroccan Arabic Dataset to Hugging Face Hub: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdc71ca4-1d63-4265-9da4-376565412836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cdba445ecbdf3e88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-cdba445ecbdf3e88/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8108985578c7418e97204b851d50e610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "212195ad28704f4e80d75485bf58a829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-cdba445ecbdf3e88/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfb55f94fd14bfaba02f7e576c4bb2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c799e10db943d093237b6170f3abf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56edbdd046f4b93903976e5d60737ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_to_hub = load_dataset(\"text\", data_files={\"train\": 'aryRoBERTa/Moroccan_Arabic_Wikipedia__aryRoBERTa.csv'})\n",
    "dataset_to_hub.push_to_hub(\"SaiedAlshahrani/Moroccan_Arabic_Wikipedia__aryRoBERTa\") # Push dataset to your huggingface account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad47b484-52b3-4139-af20-47f42d045451",
   "metadata": {
    "tags": []
   },
   "source": [
    "### * Tokenize Moroccan Arabic Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0885e52f-0d8f-450c-94ae-ee37c803e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LineByLineTextDataset\n",
    "\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer, \n",
    "    file_path=wiki_corpus, block_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f019e77-6b51-4444-944d-ed29715e2304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    0, 22270, 13419,   408,   819,  3121,   863,   530,  1016,   434,\n",
       "           696,  1016,  1324, 10217,  6088, 43889, 10530,  2758,   502,   605,\n",
       "           280,  9645,  1153, 10115,  7718,   529,   721,   307,  1016,   863,\n",
       "         21863,   360,  7718, 10478,   570,  2140, 25929,  1016,   428,   459,\n",
       "           930,  2561,  2621, 45570,  2017,   323,   570, 10183,  8771,  1309,\n",
       "           557,   422,   427,   360,   560,   599,   516,   601,   350,   621,\n",
       "           364,   404,   630,   617,   380,   618,   350,   357,   581,   531,\n",
       "           619,   620,   583,   622,   350,   364,   628,   550,   574,   350,\n",
       "           625,   364,   404,   629,   626,   360,   607,   350,   364,   339,\n",
       "           398,   580,   380,   496,   339,   470,   467,   473,   350,   364,\n",
       "           339,   398,   349,   612,   573,   380,   496,   339,   470,   467,\n",
       "           473,   391,   392,   336,   434,   696,  1297,   336,  1163,   443,\n",
       "             2])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3620b4fe-726e-491a-aba8-fa4f78ad0502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>آسفي بالأمازيغية هي مدينة مغربية جات إقليم آسفي جهة مراكش آسفي معروفة بالفخار والحوت وخصوصا السردين ومكنيين عليها حاضرة المحيط الحطة ديال آسفي جات كاطل على المحيط الأطلسي بين الجديدة والصويرة آسفي كاين بزاف دالبني قديم وتاريخي وهي من بين المدن القديمة المغرب ساكنين فيها واحد على حسب لإحصاء لعام تعليم نسبة لأمية اس ما كايعرفوش يقراو ولا يكتبو نسبة كان قاريين فوق انوي تانوي جامعة اقتصاد نسبة اس شيطين يقدرو يخدمو نسبة لبطالة اس ما خدامينش تايقلبو على خدمة نسبة اس اللي خدامين ولة ولا لعاطلين اللي سبق ليهوم خدمو نسبة اس اللي خدامين في لقطاع لخاص ولا لعاطلين اللي سبق ليهوم خدمو عيون لكلام تصنيف جهة مراكش أسفي تصنيف مدون لمغريب</s>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dataset[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e26ee86-c1d4-4fc7-af16-d108b35d7cc7",
   "metadata": {},
   "source": [
    "### * Create Data Collator for Language Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f015de56-38e1-46f4-abba-0a5649b3ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e751cc19-3234-4ed0-9ccc-69431cd679b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### * Train aryRoberta Model from Scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16261e59-9b79-473a-aef1-b377a62b2649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/aryRoBERTa is already a clone of https://huggingface.co/SaiedAlshahrani/aryRoBERTa. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    push_to_hub=True, push_to_hub_model_id=\"aryRoBERTa\",\n",
    "    output_dir=\"aryRoBERTa\", evaluation_strategy=\"no\",\n",
    "    auto_find_batch_size=True, num_train_epochs=5,\n",
    "    learning_rate=1e-4, save_total_limit=3,\n",
    "    adam_epsilon=1e-6, weight_decay=0.01,\n",
    "    adam_beta1=0.9, adam_beta2=0.98,\n",
    "    per_device_train_batch_size=128,\n",
    "    logging_steps=35, save_steps=35,\n",
    "    prediction_loss_only=False,\n",
    "    report_to=\"tensorboard\",\n",
    "    data_seed=24, seed=42,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args,\n",
    "    train_dataset=dataset, \n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1c26686-2e16-45f5-9389-68ae6bfcab5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 4673\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 185\n",
      "  Number of trainable parameters = 83504416\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='185' max='185' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [185/185 03:12, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>9.598400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>7.988900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>7.438800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>7.204400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>7.181200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to aryRoBERTa/checkpoint-35\n",
      "Configuration saved in aryRoBERTa/checkpoint-35/config.json\n",
      "Model weights saved in aryRoBERTa/checkpoint-35/pytorch_model.bin\n",
      "Saving model checkpoint to aryRoBERTa/checkpoint-70\n",
      "Configuration saved in aryRoBERTa/checkpoint-70/config.json\n",
      "Model weights saved in aryRoBERTa/checkpoint-70/pytorch_model.bin\n",
      "Saving model checkpoint to aryRoBERTa/checkpoint-105\n",
      "Configuration saved in aryRoBERTa/checkpoint-105/config.json\n",
      "Model weights saved in aryRoBERTa/checkpoint-105/pytorch_model.bin\n",
      "Saving model checkpoint to aryRoBERTa/checkpoint-140\n",
      "Configuration saved in aryRoBERTa/checkpoint-140/config.json\n",
      "Model weights saved in aryRoBERTa/checkpoint-140/pytorch_model.bin\n",
      "Deleting older checkpoint [aryRoBERTa/checkpoint-35] due to args.save_total_limit\n",
      "Saving model checkpoint to aryRoBERTa/checkpoint-175\n",
      "Configuration saved in aryRoBERTa/checkpoint-175/config.json\n",
      "Model weights saved in aryRoBERTa/checkpoint-175/pytorch_model.bin\n",
      "Deleting older checkpoint [aryRoBERTa/checkpoint-70] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d8b70\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_d8b70_level0_col0\" class=\"col_heading level0 col0\" >train_runtime</th>\n",
       "      <th id=\"T_d8b70_level0_col1\" class=\"col_heading level0 col1\" >train_samples_per_second</th>\n",
       "      <th id=\"T_d8b70_level0_col2\" class=\"col_heading level0 col2\" >train_steps_per_second</th>\n",
       "      <th id=\"T_d8b70_level0_col3\" class=\"col_heading level0 col3\" >total_flos</th>\n",
       "      <th id=\"T_d8b70_level0_col4\" class=\"col_heading level0 col4\" >train_loss</th>\n",
       "      <th id=\"T_d8b70_level0_col5\" class=\"col_heading level0 col5\" >epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_d8b70_row0_col0\" class=\"data row0 col0\" >194.247200</td>\n",
       "      <td id=\"T_d8b70_row0_col1\" class=\"data row0 col1\" >120.285000</td>\n",
       "      <td id=\"T_d8b70_row0_col2\" class=\"data row0 col2\" >0.952000</td>\n",
       "      <td id=\"T_d8b70_row0_col3\" class=\"data row0 col3\" >774708261150720.000000</td>\n",
       "      <td id=\"T_d8b70_row0_col4\" class=\"data row0 col4\" >7.833400</td>\n",
       "      <td id=\"T_d8b70_row0_col5\" class=\"data row0 col5\" >5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1b2ec566a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = trainer.train()\n",
    "\n",
    "train = pd.DataFrame().append(history.metrics, ignore_index=True)\n",
    "train.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4324be-4e23-49de-88e2-ab979928ebc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### * Push aryRoberta Model to Hugging Face Hub: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d618d694-3c25-4e2a-9ef8-2a5ba6fa397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to aryRoBERTa\n",
      "Configuration saved in aryRoBERTa/config.json\n",
      "Model weights saved in aryRoBERTa/pytorch_model.bin\n",
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858bb79c06764a75a5b0d8e67771d2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/319M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bf1cca01cf4df6b8639a46389537e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file runs/Oct28_19-53-39_naj6vyunmn/events.out.tfevents.1698522825.naj6vyunmn.748.0:   0%|          | 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/SaiedAlshahrani/aryRoBERTa\n",
      "   25d16b6..4d05cd9  main -> main\n",
      "\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Masked Language Modeling', 'type': 'fill-mask'}}\n",
      "To https://huggingface.co/SaiedAlshahrani/aryRoBERTa\n",
      "   4d05cd9..8314f05  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/SaiedAlshahrani/aryRoBERTa/commit/4d05cd9715addd67feabcce448894814de9d16cb'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(\"SaiedAlshahrani/aryRoBERTa\") # Push the trained model to your huggingface account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f02aa1e-b2a9-4892-a548-18ead2056aee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### * Save aryRoberta Model Locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "559863ed-4946-45ad-8671-916b0f10308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to aryRoBERTa\n",
      "Configuration saved in aryRoBERTa/config.json\n",
      "Model weights saved in aryRoBERTa/pytorch_model.bin\n",
      "Saving model checkpoint to aryRoBERTa\n",
      "Configuration saved in aryRoBERTa/config.json\n",
      "Model weights saved in aryRoBERTa/pytorch_model.bin\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Masked Language Modeling', 'type': 'fill-mask'}}\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"aryRoBERTa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fe7980-05bf-410e-b7ab-7d78646941a1",
   "metadata": {},
   "source": [
    "### * Test aryRoberta Using Transformers Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3eb7d3ba-d4b2-46dc-841f-ded8237e3aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "def mask_filler(prompt, top_k=None, targets=None):\n",
    "    fill = pipeline(\n",
    "        'fill-mask', \n",
    "        model='aryRoBERTa', \n",
    "        tokenizer='aryRoBERTa', \n",
    "        top_k=top_k, targets=targets\n",
    "        )\n",
    "    results = fill(prompt)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d305f5e5-535d-4037-95c9-9b0a75c98b73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.0010255323722958565,\n",
       "  'token': 844,\n",
       "  'token_str': ' إفريقيا',\n",
       "  'sequence': 'تقع دولة المغرب في قارة إفريقيا'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_filler(f'تقع دولة المغرب في قارة <mask>', top_k=10, targets=tokenizer.tokenize(' إفريقيا'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
