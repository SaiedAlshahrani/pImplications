# Word Representation Evaluations

We evaluate the **performance** of the Word Embedding Models (WEMs) using the Word Analogy evaluation task and our [Arab States Analogy Dataset (ASAD)](https://github.com/SaiedAlshahrani/performance-implications/tree/main/Word-Representation-Evals/ASAD) dataset. To measure the **impact of template-based translation**, we compare the performance of WEMs trained on the Egyptian Arabic Wikipedia edition’s corpora, which are dominated by template-based translation, to the performance of WEMs trained on Modern Standard Arabic and Moroccan Arabic Wikipedia editions’ corpora, which are not. On the other hand, to measure the **impact of bot-based generation**, we compare the performance of WEMs trained on Arabic and Moroccan Arabic corpora (with and without bot-generated articles) using the word analogy task and our [ASAD](https://github.com/SaiedAlshahrani/performance-implications/tree/main/Word-Representation-Evals/ASAD) dataset. *Please read the paper for more details about the evaluation process.*


### Word Embedding Models (WEMs):
We have trained **35** context-independent WEMs for this experiment, and due to the huge size of these models, we could **not** share them with the community. However, we share our [training scripts](https://github.com/SaiedAlshahrani/performance-implications/tree/main/Word-Representation-Evals/Training-Scripts) for these models and provide detailed documentation on the creation of Wikipedia corpora that can be found here at [Wikipedia-Corpora-Creation](https://github.com/SaiedAlshahrani/performance-implications/tree/main/Wikipedia-Corpora-Creation). 

### Evaluation Pipeline:
We share our **evaluation pipeline** of the Word Representation upstream task, including the implementation of the Word Analogy evaluation task process and the generic search algorithm that takes any Arabic word and then searches for all its possible Arabic variants (*only* Alefs, Alef Maksura, and Teh Marbuta variants). All are available at [embeddings_utils.py](https://github.com/SaiedAlshahrani/performance-implications/blob/main/Word-Representation-Evals/embeddings_utils.py). We also share the Word Representation evaluations of our WEMs here at [Word-Representation-Task.ipynb](https://github.com/SaiedAlshahrani/performance-implications/blob/main/Word-Representation-Evals/Word-Representation-Task.ipynb).